{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Things to load, import and install before starting"
      ],
      "metadata": {
        "id": "lfzxGK20MfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper #Whisper models\n",
        "!pip install jiwer #WER computation\n",
        "!pip install codecarbon #carbon footprint of my code"
      ],
      "metadata": {
        "id": "MK8PHt-6s-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from jiwer import wer\n",
        "import os\n",
        "import jiwer\n",
        "import json\n",
        "import re\n",
        "from codecarbon import EmissionsTracker\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "_wQFcYoFmGq0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only for google colab uses, to access the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive"
      ],
      "metadata": {
        "id": "TZWi7poBv9ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e3fd8b-4abf-42aa-afbf-3ae50f2515a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the models\n",
        "tiny_model = whisper.load_model(\"tiny\")\n",
        "small_model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "3X2oVyLZ218v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff11384-5104-42e5-ea09-b18dcc869ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 125MiB/s]\n",
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 108MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All function used for transcriptions, data processing and WER computation"
      ],
      "metadata": {
        "id": "wi_kZM5-I-BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transcriptions\n",
        "def transcribeAllFiles(model_v1, model_v2, path_to_folder:str):\n",
        "    \"\"\"\n",
        "    provide the transcription of all .wav files contained in a folder in a dictionnary with two different versions of the Whisper model : model_v1 and model_v2\n",
        "\n",
        "    :param str path_to_folder : path to the mother-folder which contains all .wav files, default to '.' (current folder)\n",
        "    :param whisper.model.Whisper model_v1 : model, eg. Whisper-tiny\n",
        "    :param whisper.model.Whisper model_v2 : model, eg. Whisper-small\n",
        "    \"\"\"\n",
        "\n",
        "    if path_to_folder is None:\n",
        "        path_to_folder = '.'\n",
        "    else:\n",
        "        %cd $path_to_folder\n",
        "        !pwd\n",
        "    #results is a dictionnary with the name of the file as a key and a tuple with tiny-transcription and small-transcription\n",
        "    results = {}\n",
        "    not_everything=0 #used to test, since running this function can take some time if all files are transribed\n",
        "\n",
        "    # go through all files in the current folder\n",
        "    for f in os.listdir(path_to_folder):\n",
        "        if f.endswith('.wav'): #and not_everything<5:\n",
        "            not_everything += 1\n",
        "            print(not_everything)\n",
        "            # Transcription with first model\n",
        "            tiny_result = model_v1.transcribe(f)\n",
        "            tiny_text = tiny_result[\"text\"]\n",
        "\n",
        "            # Transcription with the other model\n",
        "            small_result = model_v2.transcribe(f)\n",
        "            small_text = small_result[\"text\"]\n",
        "\n",
        "            results[f] = (tiny_text, small_text)\n",
        "\n",
        "    return results\n",
        "\n",
        "def create_json_file(input_dict, category, file_path):\n",
        "    \"\"\"\n",
        "    Converts the input dictionary and category into a json-formatted string.\n",
        "\n",
        "    :param input_dict: Dictionary with filenames as keys and tuples (tiny, small transcriptions) as values.\n",
        "    :param category: String representing the category.\n",
        "    :return: A json-formatted string.\n",
        "    \"\"\"\n",
        "    output = {\"category\": category, \"files\": []}\n",
        "\n",
        "    for filename, (tiny_transcription, small_transcription) in input_dict.items():\n",
        "        file_info = {\n",
        "            \"filename\": filename,\n",
        "            \"transcriptions\": {\n",
        "                \"tiny\": tiny_transcription,\n",
        "                \"small\": small_transcription\n",
        "            }\n",
        "        }\n",
        "        output[\"files\"].append(file_info)\n",
        "\n",
        "    json_file = json.dumps(output, indent=4)\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(json_file)\n",
        "\n",
        "# Function to create a JSON file from the results dictionary\n",
        "def create_json_file_WER(results, filename):\n",
        "    \"\"\"\n",
        "    create a JSON file from the results dictionary\n",
        "\n",
        "    :param results dict: dictionnary to convert to json file\n",
        "    :param filename str: name of the file to put json dump\n",
        "\n",
        "    \"\"\"\n",
        "    # Open the file for writing\n",
        "    with open(filename, 'w') as file:\n",
        "        # Dump the dictionary into the file as a JSON formatted string\n",
        "        json.dump(results, file, indent=4)\n",
        "\n",
        "# Display of results for test\n",
        "def display_transcriptions(results : dict):\n",
        "    \"\"\"\n",
        "    display of transcriptions\n",
        "\n",
        "    :param results dict: name of the file as a key, tuple with tiny and small transcription as value\n",
        "    \"\"\"\n",
        "    for f, (tiny_text, small_text) in results.items():\n",
        "        print(f\"File: {f}\")\n",
        "        print(f\"Tiny Model: {tiny_text}\")\n",
        "        print(f\"Small Model: {small_text}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "#evaluation visualisation --> not used for WER, just for test to understand how jiwer works\n",
        "def visualisation_evaluation(gold_data, transcriptions_dict):\n",
        "    \"\"\"\n",
        "    visualise properties of the evaluation of transcription compared to gold data (comparison of strings, WER, MER, WIL, WIP, CER)\n",
        "\n",
        "    :param gold_data\n",
        "    :param transcriptions_dict\n",
        "    \"\"\"\n",
        "\n",
        "    for fichier, (tiny_text, small_text) in transcriptions_dict.items():\n",
        "\n",
        "        out_tiny = jiwer.process_words(\n",
        "            gold_data[fichier],\n",
        "            [tiny_text],\n",
        "        )\n",
        "        print(jiwer.visualize_alignment(out_tiny))\n",
        "\n",
        "        out_small = jiwer.process_words(\n",
        "            gold_data[fichier],\n",
        "            [small_text],\n",
        "        )\n",
        "        print(jiwer.visualize_alignment(out_small))\n",
        "\n",
        "\n",
        "#gold data as a dict with only audio name and transcription\n",
        "def process_json_gold_data(path):\n",
        "    \"\"\"\n",
        "    gets the gold data from the json file and create a dictionnary with name of the file and transcription for later comparison\n",
        "\n",
        "    :param path str: path to the json file\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # match the pattern and only keep the name of the video\n",
        "    pattern = re.compile(r'(\\d+_\\d+).MP4')\n",
        "\n",
        "    #store the results\n",
        "    result = {}\n",
        "\n",
        "    # Iterate through the items and apply the regex\n",
        "    for item in data:\n",
        "        video_path = item.get(\"video_path\", \"\")\n",
        "        match = pattern.search(video_path)\n",
        "        if match:\n",
        "            # construct the new key with .wav to correspond to the audio files\n",
        "            new_key = match.group(1) + \".wav\"\n",
        "            # Assign transcription as values\n",
        "            result[new_key] = item.get(\"transcription_timestamp\", \"\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def list_subfolders(mother_folder):\n",
        "    \"\"\"\n",
        "    Returns a list of names of all subfolders within the given mother folder\n",
        "\n",
        "    :param mother_folder: Path to the mother folder\n",
        "    :return: List of subfolder names\n",
        "    \"\"\"\n",
        "    subfolders = [f.name for f in os.scandir(mother_folder) if f.is_dir()]\n",
        "    return subfolders\n",
        "\n",
        "def compute_wer(json_file, gold_data):\n",
        "    \"\"\"\n",
        "    Computes the Word Error Rate for transcriptions in a JSON file against gold data\n",
        "\n",
        "    :param json_file: Path to the JSON file containing transcriptions\n",
        "    :param gold_data: Dictionary with filenames as keys and gold transcriptions as values\n",
        "    :return: Dictionary with WER results\n",
        "    \"\"\"\n",
        "    # Read JSON file\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for file_info in data['files']:\n",
        "        filename = file_info['filename']\n",
        "        if filename in gold_data:\n",
        "            gold_transcription = gold_data[filename]\n",
        "            tiny_transcription = file_info['transcriptions']['tiny']\n",
        "            small_transcription = file_info['transcriptions']['small']\n",
        "\n",
        "            # Compute WER\n",
        "            wer_tiny = jiwer.wer(gold_transcription, tiny_transcription)\n",
        "            wer_small = jiwer.wer(gold_transcription, small_transcription)\n",
        "\n",
        "            # Store results\n",
        "            results[filename] = {\n",
        "                'tiny_wer': wer_tiny,\n",
        "                'small_wer': wer_small\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Function to calculate the arithmetic mean of 'tiny_wer' and 'small_wer' from a json file\n",
        "def calculate_wer_means(filename):\n",
        "    \"\"\"\n",
        "    calculate the arithmetic mean of 'tiny_wer' and 'small_wer' from a json file\n",
        "\n",
        "    :param filename\n",
        "\n",
        "    \"\"\"\n",
        "    # Read the JSON file and load it into a dictionary\n",
        "    with open(filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract all 'tiny_wer' and 'small_wer' values\n",
        "    tiny_wer_values = [details['tiny_wer'] for details in data.values()]\n",
        "    small_wer_values = [details['small_wer'] for details in data.values()]\n",
        "\n",
        "    # Calculate the arithmetic means\n",
        "    tiny_wer_mean = mean(tiny_wer_values)\n",
        "    small_wer_mean = mean(small_wer_values)\n",
        "\n",
        "    return tiny_wer_mean, small_wer_mean\n",
        "\n"
      ],
      "metadata": {
        "id": "0G8k3mjnnJJT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcriptions for not noisy speech data"
      ],
      "metadata": {
        "id": "loxyuJ0WK3D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#original speech files\n",
        "ori_transcriptions = transcribeAllFiles(tiny_model, small_model, path_to_folder= '/content/drive/My Drive/wav_data/')\n",
        "\n",
        "create_json_file(ori_transcriptions, \"original_transcriptions\", '/content/drive/My Drive/transcriptions/original_transcriptions.json')\n",
        "\n",
        "#--------------------\n",
        "#display_transcriptions(transcriptions)\n",
        "\n",
        "#visualisation_evaluation(gold_data, transcriptions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnVenxkQsaBD",
        "outputId": "39f3e4eb-2f1f-4c59-d8b7-bebfc014483d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   is technology making our attention span shorter?     ah technology is definitely making our attention span shorter. um  with social media. with apps. uh you get your one minute video and you know these days if it's  anything longer than that we can't be bothered.   um we only wanna you know read the comments we only wanna you know go through and get the gist of things and  um I know that if  you know you   see a long paragraph on the internet. you will look and most people say well I'm not reading that.  can someone tell me what it says? it's too long I'm not reading it.   ah so I think that um different apps particularly Instagram where everything's gotta be   quick and you know you you gotta get the short version of something in order to care.  uh I think that's definitely making um our attention span shorter.  um  social media, Facebook  you know you make your short post. if the post's too long no one wants to read it.  um even YouTube videos you know once we see oh this video  fifteen minutes long. I'm not watching that. you know  everything has to be  quick and to the point when it comes to social media.  and I think that that does create a short attention span for most people.    \n",
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcription of noisy speech"
      ],
      "metadata": {
        "id": "RqvnvziMLheK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noisy speeches\n",
        "\n",
        "folder = '/content/drive/My Drive/noisy_speech_0dbSNR'\n",
        "\n",
        "tracker = EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "!mkdir \"transcriptions_0dbSNR\" #change for 10dbSNR\n",
        "\n",
        "for category in list_subfolders(folder):\n",
        "    !mkdir $category\n",
        "    if category not in (\"cat\", \"chainsaw\", \"crickets\", \"crying_baby\", \"engine\"):\n",
        "        transcriptions = transcribeAllFiles(tiny_model, small_model, path_to_folder= f'{folder}/{category}')\n",
        "        create_json_file(transcriptions, category, f'/content/drive/My Drive/transcriptions_0dbSNR/{category}.json')\n",
        "\n",
        "emissions : float = tracker.stop()\n",
        "print(f\"Emissions: {emissions} kg\")"
      ],
      "metadata": {
        "id": "zR9MhUiyxRTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WER computation"
      ],
      "metadata": {
        "id": "18YcpiLWL5N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_data = process_json_gold_data('/content/drive/My Drive/gold/cleaned_transcriptions.json')\n",
        "\n",
        "categories = ('original_transcriptions', 'cat', 'chainsaw', 'crickets', 'crying_baby', 'engine', 'glass_breaking', 'helicopter', 'keyboard_typing', 'laughing', 'vacuum_cleaner')\n",
        "SNR_10db = {}\n",
        "SNR_0db = {}\n",
        "\n",
        "\n",
        "for cat in categories:\n",
        "    snr = ''\n",
        "    if cat != 'original_transcriptions':\n",
        "        snr= '_0dbSNR'\n",
        "    create_json_file_WER(compute_wer(f'/content/drive/My Drive/transcriptions{snr}/{cat}.json', gold_data), f'/content/drive/My Drive/WERs/WERs_0dbSNR/wer_{cat}.json' )\n",
        "    print(snr + \" \" + cat + \" tiny: \" + str(calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_0dbSNR/wer_{cat}.json')[0]) + \" small: \" + str(calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_0dbSNR/wer_{cat}.json')[1]))\n",
        "    SNR_0db[cat]= calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_0dbSNR/wer_{cat}.json')\n",
        "\n",
        "\n",
        "\n",
        "for cat in categories:\n",
        "    snr = ''\n",
        "    if cat != 'original_transcriptions':\n",
        "        snr= '_10dbSNR'\n",
        "    create_json_file_WER(compute_wer(f'/content/drive/My Drive/transcriptions{snr}/{cat}.json', gold_data), f'/content/drive/My Drive/WERs/WERs_10dbSNR/wer_{cat}.json' )\n",
        "    print(snr + \" \" + cat + \" tiny: \" + str(calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_10dbSNR/wer_{cat}.json')[0]) + \" small: \" + str(calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_10dbSNR/wer_{cat}.json')[1]))\n",
        "    SNR_10db[cat]= calculate_wer_means(f'/content/drive/My Drive/WERs/WERs_10dbSNR/wer_{cat}.json')\n",
        "\n",
        "\n",
        "print(SNR_10db)\n",
        "print(SNR_0db)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "0sEO_6PBMP9Z",
        "outputId": "d5231d02-8d36-4756-af8f-e209d9ba7173"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   is technology making our attention span shorter?     ah technology is definitely making our attention span shorter. um  with social media. with apps. uh you get your one minute video and you know these days if it's  anything longer than that we can't be bothered.   um we only wanna you know read the comments we only wanna you know go through and get the gist of things and  um I know that if  you know you   see a long paragraph on the internet. you will look and most people say well I'm not reading that.  can someone tell me what it says? it's too long I'm not reading it.   ah so I think that um different apps particularly Instagram where everything's gotta be   quick and you know you you gotta get the short version of something in order to care.  uh I think that's definitely making um our attention span shorter.  um  social media, Facebook  you know you make your short post. if the post's too long no one wants to read it.  um even YouTube videos you know once we see oh this video  fifteen minutes long. I'm not watching that. you know  everything has to be  quick and to the point when it comes to social media.  and I think that that does create a short attention span for most people.    \n",
            "<class 'dict'>\n",
            " original_transcriptions tiny: 0.3441453995886726 small: 0.3093357587677546\n",
            "_0dbSNR cat tiny: 0.46530480732160157 small: 0.32938837049533437\n",
            "_0dbSNR chainsaw tiny: 0.8150546004478594 small: 0.5432472564401448\n",
            "_0dbSNR crickets tiny: 0.6048223247475419 small: 0.37517104491472875\n",
            "_0dbSNR crying_baby tiny: 0.6600574426829464 small: 0.39258185758271863\n",
            "_0dbSNR engine tiny: 0.5115675599349435 small: 0.32901799376054575\n",
            "_0dbSNR glass_breaking tiny: 0.47635226734363106 small: 0.33927718810556046\n",
            "_0dbSNR helicopter tiny: 0.6951238163753957 small: 0.452675862952258\n",
            "_0dbSNR keyboard_typing tiny: 0.44046928105828875 small: 0.38387985187176843\n",
            "_0dbSNR laughing tiny: 0.5806914453480775 small: 0.41692266917875465\n",
            "_0dbSNR vacuum_cleaner tiny: 0.7336488449231192 small: 0.46953937657297096\n",
            " original_transcriptions tiny: 0.3441453995886726 small: 0.3093357587677546\n",
            "_10dbSNR cat tiny: 0.34177152614173506 small: 0.30983352489052074\n",
            "_10dbSNR chainsaw tiny: 0.3462905214270462 small: 0.30849805480505066\n",
            "_10dbSNR crickets tiny: 0.3454042228508712 small: 0.3102463065533024\n",
            "_10dbSNR crying_baby tiny: 0.3434909045222013 small: 0.3092993368563327\n",
            "_10dbSNR engine tiny: 0.3784358011370782 small: 0.3082900188450932\n",
            "_10dbSNR glass_breaking tiny: 0.40874875406409056 small: 0.29100910670194613\n",
            "_10dbSNR helicopter tiny: 0.4363509958589684 small: 0.3084696155634216\n",
            "_10dbSNR keyboard_typing tiny: 0.3712326399762779 small: 0.33621336199437724\n",
            "_10dbSNR laughing tiny: 0.4097435176286729 small: 0.3187636621891275\n",
            "_10dbSNR vacuum_cleaner tiny: 0.47227292687102856 small: 0.3379665687654406\n",
            "{'original_transcriptions': (0.3441453995886726, 0.3093357587677546), 'cat': (0.34177152614173506, 0.30983352489052074), 'chainsaw': (0.3462905214270462, 0.30849805480505066), 'crickets': (0.3454042228508712, 0.3102463065533024), 'crying_baby': (0.3434909045222013, 0.3092993368563327), 'engine': (0.3784358011370782, 0.3082900188450932), 'glass_breaking': (0.40874875406409056, 0.29100910670194613), 'helicopter': (0.4363509958589684, 0.3084696155634216), 'keyboard_typing': (0.3712326399762779, 0.33621336199437724), 'laughing': (0.4097435176286729, 0.3187636621891275), 'vacuum_cleaner': (0.47227292687102856, 0.3379665687654406)}\n",
            "{'original_transcriptions': (0.3441453995886726, 0.3093357587677546), 'cat': (0.46530480732160157, 0.32938837049533437), 'chainsaw': (0.8150546004478594, 0.5432472564401448), 'crickets': (0.6048223247475419, 0.37517104491472875), 'crying_baby': (0.6600574426829464, 0.39258185758271863), 'engine': (0.5115675599349435, 0.32901799376054575), 'glass_breaking': (0.47635226734363106, 0.33927718810556046), 'helicopter': (0.6951238163753957, 0.452675862952258), 'keyboard_typing': (0.44046928105828875, 0.38387985187176843), 'laughing': (0.5806914453480775, 0.41692266917875465), 'vacuum_cleaner': (0.7336488449231192, 0.46953937657297096)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwer_cat = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/cat.json', gold_data)\\nwer_chainsaw = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/chainsaw.json', gold_data)\\nwer_crickets = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/crickets.json', gold_data)\\nwer_crying_baby = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/crying_baby.json', gold_data)\\nwer_original_transcriptions = compute_wer('/content/drive/My Drive/transcriptions/original_transcriptions.json', gold_data)\\nwer_engine = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/engine.json', gold_data)\\nwer_glass_breaking = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/glass_breaking.json', gold_data)\\nwer_helicopter = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/helicopter.json', gold_data)\\nwer_keyboard_typing = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/keyboard_typing.json', gold_data)\\nwer_laughing = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/laughing.json', gold_data)\\nwer_vacuum_cleaner = compute_wer('/content/drive/My Drive/transcriptions_0dbSNR/vacuum_cleaner.json', gold_data)\\n\\n\\ncreate_json_file_WER(wer_original_transcriptions, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_original_transcriptions.json' )\\ncreate_json_file_WER(wer_cat, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_cat.json' )\\ncreate_json_file_WER(wer_chainsaw, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_chainsaw.json' )\\ncreate_json_file_WER(wer_crickets, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_crickets.json' )\\ncreate_json_file_WER(wer_crying_baby, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_crying_baby.json' )\\ncreate_json_file_WER(wer_engine, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_engine.json' )\\ncreate_json_file_WER(wer_glass_breaking, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_glass_breaking.json' )\\ncreate_json_file_WER(wer_helicopter, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_helicopter.json' )\\ncreate_json_file_WER(wer_keyboard_typing, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_keyboard_typing.json' )\\ncreate_json_file_WER(wer_laughing, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_laughing.json' )\\ncreate_json_file_WER(wer_vacuum_cleaner, '/content/drive/My Drive/WERs/WERs_0dbSNR/wer_vacuum_cleaner.json' )\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}